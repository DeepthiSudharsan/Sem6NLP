{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><font color='black'> DEEPTHI SUDHARSAN (ROLL NUMBER : CB.EN.U4AIE19022)</font></center>\n",
    "## <center><font color='black'> AI IN NLP ASSIGNMENT 3 </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a python code to implement unigram, bi-gram, and trigram probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text\n",
    "text = \"The best way to evaluate the performance of a language model is to embed it in an application and \" \\\n",
    "\"measure how much the application improves. Such end-to-end evaluation is called extrinsic evaluation. \"\\\n",
    "\"Extrinsic evaluation is the only way to know if a particular improvement in a component is really going to \"\\\n",
    "\"help the task at hand. Thus, for speech recognition, we can compare the performance of two language models by \"\\\n",
    "\"running the speech recognizer twice, once with each language model, and seeing which gives the more accurate \"\\\n",
    "\"transcription.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The best way to evaluate the performance of a language model is to embed it in an application and measure how much the application improves',\n",
       " 'Such end-to-end evaluation is called extrinsic evaluation',\n",
       " 'Extrinsic evaluation is the only way to know if a particular improvement in a component is really going to help the task at hand',\n",
       " 'Thus, for speech recognition, we can compare the performance of two language models by running the speech recognizer twice, once with each language model, and seeing which gives the more accurate transcription.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = text.split('. ') # splitting paragraph to sentences based on fullstop\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the best way to evaluate the performance of a language model is to embed it in an application and measure how much the application improves',\n",
       " 'such end to end evaluation is called extrinsic evaluation',\n",
       " 'extrinsic evaluation is the only way to know if a particular improvement in a component is really going to help the task at hand',\n",
       " 'thus for speech recognition we can compare the performance of two language models by running the speech recognizer twice once with each language model and seeing which gives the more accurate transcription']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bit of preprocessing\n",
    "import re\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = re.sub('[^a-zA-Z\\s]', ' ', sentences[i]).rstrip() # removing special characters\n",
    "    sentences[i] = sentences[i].replace(\"  \",\" \").lower() # removing extra whitspaces and converting text to lowercase\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> the best way to evaluate the performance of a language model is to embed it in an application and measure how much the application improves </s>',\n",
       " '<s> such end to end evaluation is called extrinsic evaluation </s>',\n",
       " '<s> extrinsic evaluation is the only way to know if a particular improvement in a component is really going to help the task at hand </s>',\n",
       " '<s> thus for speech recognition we can compare the performance of two language models by running the speech recognizer twice once with each language model and seeing which gives the more accurate transcription </s>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blines = [\"<s> \" + s + \" </s>\" for s in sentences] # appending start and end tags for bigrams\n",
    "blines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s1> <s> the best way to evaluate the performance of a language model is to embed it in an application and measure how much the application improves </s> </s1>',\n",
       " '<s1> <s> such end to end evaluation is called extrinsic evaluation </s> </s1>',\n",
       " '<s1> <s> extrinsic evaluation is the only way to know if a particular improvement in a component is really going to help the task at hand </s> </s1>',\n",
       " '<s1> <s> thus for speech recognition we can compare the performance of two language models by running the speech recognizer twice once with each language model and seeing which gives the more accurate transcription </s> </s1>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlines = [\"<s1> \" + s + \" </s1>\" for s in blines] # appending start and end tags for trigrams\n",
    "tlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "# function definition to split sentences to ngrams\n",
    "def N_gram(words,n):\n",
    "    ngrams_list = []\n",
    "    for i in range(len(words)-n+1):\n",
    "        temp_list = [words[j] for j in range(i,i+n)]\n",
    "        ngrams_list.append(\" \".join(temp_list))\n",
    "    return ngrams_list\n",
    "\n",
    "# function definition for unigram probability\n",
    "\n",
    "def unigram_probability(sentence):\n",
    "    # to store the probabilities\n",
    "    probs = defaultdict(list)\n",
    "    unigrams = []\n",
    "    for s in sentence:\n",
    "        # split sentence to words\n",
    "        w = s.split()\n",
    "        # getting the n grams and n-1 grams\n",
    "        unigrams.extend(N_gram(w,1))\n",
    "    nlength = len(unigrams)\n",
    "    # Term frequencies of the unigrams\n",
    "    unigramsTF = dict(Counter(unigrams))\n",
    "    words_key = list(unigramsTF.keys())\n",
    "    # loop through and calculate probability and add it to dict\n",
    "    for i in range(len(unigramsTF)):\n",
    "        probs[words_key[i]] = unigramsTF[words_key[i]]/nlength\n",
    "    return dict(probs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition to calculate n gram probabilites\n",
    "def ngram_probability(sentence,n):\n",
    "    # to store the probabilities\n",
    "    probs = defaultdict(list)\n",
    "    ngrams = []\n",
    "    prev = []\n",
    "    for s in sentence:\n",
    "        # split sentence to words\n",
    "        w = s.split()\n",
    "        # getting the n grams and n-1 grams\n",
    "        ngrams.extend(N_gram(w,n))\n",
    "        prev.extend(N_gram(w,n-1))\n",
    "    words = ' '.join(sentence).split()\n",
    "    nlength = len(N_gram(words,n))\n",
    "    # Term frequencies of the n grams and n-1 grams\n",
    "    ngramsTF = dict(Counter(ngrams))\n",
    "    prevTF = dict(Counter(prev))\n",
    "    # store the key\n",
    "    probskey = \"\"\n",
    "    # loop through and calculate probability and add it to dict\n",
    "    for i in range(nlength):\n",
    "        j = i + n - 1\n",
    "        prevwords =  ' '.join(words[j-n+1:j])\n",
    "        curr = words[j]\n",
    "        probskey = \"P(\" + curr + \"|\" + prevwords + \")\"\n",
    "        val = prevwords + \" \" + curr\n",
    "        if prevTF.get(prevwords) != None:\n",
    "            probs[probskey] = ngramsTF.get(val,0.0) / prevTF.get(prevwords)\n",
    "        else:\n",
    "            probs[probskey] = 0.0\n",
    "    return dict(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0.08888888888888889,\n",
       " 'best': 0.011111111111111112,\n",
       " 'way': 0.022222222222222223,\n",
       " 'to': 0.05555555555555555,\n",
       " 'evaluate': 0.011111111111111112,\n",
       " 'performance': 0.022222222222222223,\n",
       " 'of': 0.022222222222222223,\n",
       " 'a': 0.03333333333333333,\n",
       " 'language': 0.03333333333333333,\n",
       " 'model': 0.022222222222222223,\n",
       " 'is': 0.044444444444444446,\n",
       " 'embed': 0.011111111111111112,\n",
       " 'it': 0.011111111111111112,\n",
       " 'in': 0.022222222222222223,\n",
       " 'an': 0.011111111111111112,\n",
       " 'application': 0.022222222222222223,\n",
       " 'and': 0.022222222222222223,\n",
       " 'measure': 0.011111111111111112,\n",
       " 'how': 0.011111111111111112,\n",
       " 'much': 0.011111111111111112,\n",
       " 'improves': 0.011111111111111112,\n",
       " 'such': 0.011111111111111112,\n",
       " 'end': 0.022222222222222223,\n",
       " 'evaluation': 0.03333333333333333,\n",
       " 'called': 0.011111111111111112,\n",
       " 'extrinsic': 0.022222222222222223,\n",
       " 'only': 0.011111111111111112,\n",
       " 'know': 0.011111111111111112,\n",
       " 'if': 0.011111111111111112,\n",
       " 'particular': 0.011111111111111112,\n",
       " 'improvement': 0.011111111111111112,\n",
       " 'component': 0.011111111111111112,\n",
       " 'really': 0.011111111111111112,\n",
       " 'going': 0.011111111111111112,\n",
       " 'help': 0.011111111111111112,\n",
       " 'task': 0.011111111111111112,\n",
       " 'at': 0.011111111111111112,\n",
       " 'hand': 0.011111111111111112,\n",
       " 'thus': 0.011111111111111112,\n",
       " 'for': 0.011111111111111112,\n",
       " 'speech': 0.022222222222222223,\n",
       " 'recognition': 0.011111111111111112,\n",
       " 'we': 0.011111111111111112,\n",
       " 'can': 0.011111111111111112,\n",
       " 'compare': 0.011111111111111112,\n",
       " 'two': 0.011111111111111112,\n",
       " 'models': 0.011111111111111112,\n",
       " 'by': 0.011111111111111112,\n",
       " 'running': 0.011111111111111112,\n",
       " 'recognizer': 0.011111111111111112,\n",
       " 'twice': 0.011111111111111112,\n",
       " 'once': 0.011111111111111112,\n",
       " 'with': 0.011111111111111112,\n",
       " 'each': 0.011111111111111112,\n",
       " 'seeing': 0.011111111111111112,\n",
       " 'which': 0.011111111111111112,\n",
       " 'gives': 0.011111111111111112,\n",
       " 'more': 0.011111111111111112,\n",
       " 'accurate': 0.011111111111111112,\n",
       " 'transcription': 0.011111111111111112}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_probability(sentences) # function call to print unigram probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P(the|<s>)': 0.25,\n",
       " 'P(best|the)': 0.125,\n",
       " 'P(way|best)': 1.0,\n",
       " 'P(to|way)': 1.0,\n",
       " 'P(evaluate|to)': 0.2,\n",
       " 'P(the|evaluate)': 1.0,\n",
       " 'P(performance|the)': 0.25,\n",
       " 'P(of|performance)': 1.0,\n",
       " 'P(a|of)': 0.5,\n",
       " 'P(language|a)': 0.3333333333333333,\n",
       " 'P(model|language)': 0.6666666666666666,\n",
       " 'P(is|model)': 0.5,\n",
       " 'P(to|is)': 0.25,\n",
       " 'P(embed|to)': 0.2,\n",
       " 'P(it|embed)': 1.0,\n",
       " 'P(in|it)': 1.0,\n",
       " 'P(an|in)': 0.5,\n",
       " 'P(application|an)': 1.0,\n",
       " 'P(and|application)': 0.5,\n",
       " 'P(measure|and)': 0.5,\n",
       " 'P(how|measure)': 1.0,\n",
       " 'P(much|how)': 1.0,\n",
       " 'P(the|much)': 1.0,\n",
       " 'P(application|the)': 0.125,\n",
       " 'P(improves|application)': 0.5,\n",
       " 'P(</s>|improves)': 1.0,\n",
       " 'P(<s>|</s>)': 0.0,\n",
       " 'P(such|<s>)': 0.25,\n",
       " 'P(end|such)': 1.0,\n",
       " 'P(to|end)': 0.5,\n",
       " 'P(end|to)': 0.2,\n",
       " 'P(evaluation|end)': 0.5,\n",
       " 'P(is|evaluation)': 0.6666666666666666,\n",
       " 'P(called|is)': 0.25,\n",
       " 'P(extrinsic|called)': 1.0,\n",
       " 'P(evaluation|extrinsic)': 1.0,\n",
       " 'P(</s>|evaluation)': 0.3333333333333333,\n",
       " 'P(extrinsic|<s>)': 0.25,\n",
       " 'P(the|is)': 0.25,\n",
       " 'P(only|the)': 0.125,\n",
       " 'P(way|only)': 1.0,\n",
       " 'P(know|to)': 0.2,\n",
       " 'P(if|know)': 1.0,\n",
       " 'P(a|if)': 1.0,\n",
       " 'P(particular|a)': 0.3333333333333333,\n",
       " 'P(improvement|particular)': 1.0,\n",
       " 'P(in|improvement)': 1.0,\n",
       " 'P(a|in)': 0.5,\n",
       " 'P(component|a)': 0.3333333333333333,\n",
       " 'P(is|component)': 1.0,\n",
       " 'P(really|is)': 0.25,\n",
       " 'P(going|really)': 1.0,\n",
       " 'P(to|going)': 1.0,\n",
       " 'P(help|to)': 0.2,\n",
       " 'P(the|help)': 1.0,\n",
       " 'P(task|the)': 0.125,\n",
       " 'P(at|task)': 1.0,\n",
       " 'P(hand|at)': 1.0,\n",
       " 'P(</s>|hand)': 1.0,\n",
       " 'P(thus|<s>)': 0.25,\n",
       " 'P(for|thus)': 1.0,\n",
       " 'P(speech|for)': 1.0,\n",
       " 'P(recognition|speech)': 0.5,\n",
       " 'P(we|recognition)': 1.0,\n",
       " 'P(can|we)': 1.0,\n",
       " 'P(compare|can)': 1.0,\n",
       " 'P(the|compare)': 1.0,\n",
       " 'P(two|of)': 0.5,\n",
       " 'P(language|two)': 1.0,\n",
       " 'P(models|language)': 0.3333333333333333,\n",
       " 'P(by|models)': 1.0,\n",
       " 'P(running|by)': 1.0,\n",
       " 'P(the|running)': 1.0,\n",
       " 'P(speech|the)': 0.125,\n",
       " 'P(recognizer|speech)': 0.5,\n",
       " 'P(twice|recognizer)': 1.0,\n",
       " 'P(once|twice)': 1.0,\n",
       " 'P(with|once)': 1.0,\n",
       " 'P(each|with)': 1.0,\n",
       " 'P(language|each)': 1.0,\n",
       " 'P(and|model)': 0.5,\n",
       " 'P(seeing|and)': 0.5,\n",
       " 'P(which|seeing)': 1.0,\n",
       " 'P(gives|which)': 1.0,\n",
       " 'P(the|gives)': 1.0,\n",
       " 'P(more|the)': 0.125,\n",
       " 'P(accurate|more)': 1.0,\n",
       " 'P(transcription|accurate)': 1.0,\n",
       " 'P(</s>|transcription)': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_probability(blines,2) # function call to print bigram probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P(the|<s1> <s>)': 0.25,\n",
       " 'P(best|<s> the)': 1.0,\n",
       " 'P(way|the best)': 1.0,\n",
       " 'P(to|best way)': 1.0,\n",
       " 'P(evaluate|way to)': 0.5,\n",
       " 'P(the|to evaluate)': 1.0,\n",
       " 'P(performance|evaluate the)': 1.0,\n",
       " 'P(of|the performance)': 1.0,\n",
       " 'P(a|performance of)': 0.5,\n",
       " 'P(language|of a)': 1.0,\n",
       " 'P(model|a language)': 1.0,\n",
       " 'P(is|language model)': 0.5,\n",
       " 'P(to|model is)': 1.0,\n",
       " 'P(embed|is to)': 1.0,\n",
       " 'P(it|to embed)': 1.0,\n",
       " 'P(in|embed it)': 1.0,\n",
       " 'P(an|it in)': 1.0,\n",
       " 'P(application|in an)': 1.0,\n",
       " 'P(and|an application)': 1.0,\n",
       " 'P(measure|application and)': 1.0,\n",
       " 'P(how|and measure)': 1.0,\n",
       " 'P(much|measure how)': 1.0,\n",
       " 'P(the|how much)': 1.0,\n",
       " 'P(application|much the)': 1.0,\n",
       " 'P(improves|the application)': 1.0,\n",
       " 'P(</s>|application improves)': 1.0,\n",
       " 'P(</s1>|improves </s>)': 1.0,\n",
       " 'P(<s1>|</s> </s1>)': 0.0,\n",
       " 'P(<s>|</s1> <s1>)': 0.0,\n",
       " 'P(such|<s1> <s>)': 0.25,\n",
       " 'P(end|<s> such)': 1.0,\n",
       " 'P(to|such end)': 1.0,\n",
       " 'P(end|end to)': 1.0,\n",
       " 'P(evaluation|to end)': 1.0,\n",
       " 'P(is|end evaluation)': 1.0,\n",
       " 'P(called|evaluation is)': 0.5,\n",
       " 'P(extrinsic|is called)': 1.0,\n",
       " 'P(evaluation|called extrinsic)': 1.0,\n",
       " 'P(</s>|extrinsic evaluation)': 0.5,\n",
       " 'P(</s1>|evaluation </s>)': 1.0,\n",
       " 'P(extrinsic|<s1> <s>)': 0.25,\n",
       " 'P(evaluation|<s> extrinsic)': 1.0,\n",
       " 'P(is|extrinsic evaluation)': 0.5,\n",
       " 'P(the|evaluation is)': 0.5,\n",
       " 'P(only|is the)': 1.0,\n",
       " 'P(way|the only)': 1.0,\n",
       " 'P(to|only way)': 1.0,\n",
       " 'P(know|way to)': 0.5,\n",
       " 'P(if|to know)': 1.0,\n",
       " 'P(a|know if)': 1.0,\n",
       " 'P(particular|if a)': 1.0,\n",
       " 'P(improvement|a particular)': 1.0,\n",
       " 'P(in|particular improvement)': 1.0,\n",
       " 'P(a|improvement in)': 1.0,\n",
       " 'P(component|in a)': 1.0,\n",
       " 'P(is|a component)': 1.0,\n",
       " 'P(really|component is)': 1.0,\n",
       " 'P(going|is really)': 1.0,\n",
       " 'P(to|really going)': 1.0,\n",
       " 'P(help|going to)': 1.0,\n",
       " 'P(the|to help)': 1.0,\n",
       " 'P(task|help the)': 1.0,\n",
       " 'P(at|the task)': 1.0,\n",
       " 'P(hand|task at)': 1.0,\n",
       " 'P(</s>|at hand)': 1.0,\n",
       " 'P(</s1>|hand </s>)': 1.0,\n",
       " 'P(thus|<s1> <s>)': 0.25,\n",
       " 'P(for|<s> thus)': 1.0,\n",
       " 'P(speech|thus for)': 1.0,\n",
       " 'P(recognition|for speech)': 1.0,\n",
       " 'P(we|speech recognition)': 1.0,\n",
       " 'P(can|recognition we)': 1.0,\n",
       " 'P(compare|we can)': 1.0,\n",
       " 'P(the|can compare)': 1.0,\n",
       " 'P(performance|compare the)': 1.0,\n",
       " 'P(two|performance of)': 0.5,\n",
       " 'P(language|of two)': 1.0,\n",
       " 'P(models|two language)': 1.0,\n",
       " 'P(by|language models)': 1.0,\n",
       " 'P(running|models by)': 1.0,\n",
       " 'P(the|by running)': 1.0,\n",
       " 'P(speech|running the)': 1.0,\n",
       " 'P(recognizer|the speech)': 1.0,\n",
       " 'P(twice|speech recognizer)': 1.0,\n",
       " 'P(once|recognizer twice)': 1.0,\n",
       " 'P(with|twice once)': 1.0,\n",
       " 'P(each|once with)': 1.0,\n",
       " 'P(language|with each)': 1.0,\n",
       " 'P(model|each language)': 1.0,\n",
       " 'P(and|language model)': 0.5,\n",
       " 'P(seeing|model and)': 1.0,\n",
       " 'P(which|and seeing)': 1.0,\n",
       " 'P(gives|seeing which)': 1.0,\n",
       " 'P(the|which gives)': 1.0,\n",
       " 'P(more|gives the)': 1.0,\n",
       " 'P(accurate|the more)': 1.0,\n",
       " 'P(transcription|more accurate)': 1.0,\n",
       " 'P(</s>|accurate transcription)': 1.0,\n",
       " 'P(</s1>|transcription </s>)': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_probability(tlines,3) # function call to print trigram probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a python code to implement bag-of-words representation of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best way evaluate performance language model embed application measure much application improves',\n",
       " 'end end evaluation called extrinsic evaluation',\n",
       " 'extrinsic evaluation way know particular improvement component really going help task hand',\n",
       " 'thus speech recognition compare performance two language models running speech recognizer twice language model seeing gives accurate transcription']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a copy of the original sentences\n",
    "filteredsent = sentences.copy()\n",
    "\n",
    "# some of the stop words list\n",
    "all_stopwords = [\"each\",\"such\", \"in\", \"only\", \"if\", \"for\", \"it\", \"with\", \"which\", \"by\", \"how\", \"an\", \"more\", \"once\",\n",
    "                 \"and\", \"the\", \"to\", \"of\", \"we\", \"a\", \"is\", \"can\", \"at\"]\n",
    "# for each word in each sentence we are checking if they are stop words, and if they are stop words we are removing it\n",
    "i = 0\n",
    "for s in filteredsent:\n",
    "    tmp = []\n",
    "    for w in s.split():\n",
    "        if w not in all_stopwords:\n",
    "            tmp.append(w)\n",
    "    sentences[i] = \" \".join(tmp)\n",
    "    i = i + 1\n",
    "# sentences list post removing stopwords            \n",
    "sentences            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "        0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "wlist = []\n",
    "for s in sentences:\n",
    "    # split sentence to words\n",
    "    w = s.split()\n",
    "    wlist.extend(N_gram(w,1))\n",
    "V = list(set(wlist))\n",
    "\n",
    "# creating matrix of zeros\n",
    "BoW = np.zeros((len(sentences),len(V)),dtype = int)\n",
    "# if a word from the corpus is come across in a sentences, then add 1 in that position of the zero matrix\n",
    "for i in range(len(sentences)):\n",
    "    for j in sentences[i].split():\n",
    "            BoW[i,V.index(j)] = BoW[i,V.index(j)] + 1\n",
    "BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thus</th>\n",
       "      <th>going</th>\n",
       "      <th>models</th>\n",
       "      <th>task</th>\n",
       "      <th>seeing</th>\n",
       "      <th>language</th>\n",
       "      <th>extrinsic</th>\n",
       "      <th>embed</th>\n",
       "      <th>help</th>\n",
       "      <th>know</th>\n",
       "      <th>recognizer</th>\n",
       "      <th>improves</th>\n",
       "      <th>much</th>\n",
       "      <th>speech</th>\n",
       "      <th>particular</th>\n",
       "      <th>evaluate</th>\n",
       "      <th>measure</th>\n",
       "      <th>model</th>\n",
       "      <th>improvement</th>\n",
       "      <th>gives</th>\n",
       "      <th>end</th>\n",
       "      <th>way</th>\n",
       "      <th>component</th>\n",
       "      <th>running</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>hand</th>\n",
       "      <th>recognition</th>\n",
       "      <th>best</th>\n",
       "      <th>accurate</th>\n",
       "      <th>twice</th>\n",
       "      <th>application</th>\n",
       "      <th>two</th>\n",
       "      <th>performance</th>\n",
       "      <th>compare</th>\n",
       "      <th>called</th>\n",
       "      <th>transcription</th>\n",
       "      <th>really</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thus  going  models  task  seeing  language  extrinsic  embed  help  know  \\\n",
       "0     0      0       0     0       0         1          0      1     0     0   \n",
       "1     0      0       0     0       0         0          1      0     0     0   \n",
       "2     0      1       0     1       0         0          1      0     1     1   \n",
       "3     1      0       1     0       1         2          0      0     0     0   \n",
       "\n",
       "   recognizer  improves  much  speech  particular  evaluate  measure  model  \\\n",
       "0           0         1     1       0           0         1        1      1   \n",
       "1           0         0     0       0           0         0        0      0   \n",
       "2           0         0     0       0           1         0        0      0   \n",
       "3           1         0     0       2           0         0        0      1   \n",
       "\n",
       "   improvement  gives  end  way  component  running  evaluation  hand  \\\n",
       "0            0      0    0    1          0        0           0     0   \n",
       "1            0      0    2    0          0        0           2     0   \n",
       "2            1      0    0    1          1        0           1     1   \n",
       "3            0      1    0    0          0        1           0     0   \n",
       "\n",
       "   recognition  best  accurate  twice  application  two  performance  compare  \\\n",
       "0            0     1         0      0            2    0            1        0   \n",
       "1            0     0         0      0            0    0            0        0   \n",
       "2            0     0         0      0            0    0            0        0   \n",
       "3            1     0         1      1            0    1            1        1   \n",
       "\n",
       "   called  transcription  really  \n",
       "0       0              0       0  \n",
       "1       1              0       0  \n",
       "2       0              0       1  \n",
       "3       0              1       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# settings to display all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# converting ndarray to DF\n",
    "BoW_df = pd.DataFrame(BoW, columns = V)\n",
    "BoW_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a python code to implement TF-IDF representation of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentence_0</th>\n",
       "      <th>Sentence_1</th>\n",
       "      <th>Sentence_2</th>\n",
       "      <th>Sentence_3</th>\n",
       "      <th>TF_0</th>\n",
       "      <th>TF_1</th>\n",
       "      <th>TF_2</th>\n",
       "      <th>TF_3</th>\n",
       "      <th>IDF</th>\n",
       "      <th>TFIDF_0</th>\n",
       "      <th>TFIDF_1</th>\n",
       "      <th>TFIDF_2</th>\n",
       "      <th>TFIDF_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>thus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>going</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>models</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>task</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>seeing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>extrinsic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>embed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>help</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>know</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>recognizer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>improves</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>much</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>speech</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>particular</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>evaluate</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>measure</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>model</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>improvement</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>gives</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>end</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>way</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>component</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>running</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>evaluation</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100343</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>hand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>recognition</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>accurate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>twice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>application</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.100343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>two</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>compare</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>called</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>transcription</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>really</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Sentence_0  Sentence_1  Sentence_2  Sentence_3      TF_0  \\\n",
       "0            thus           0           0           0           1  0.000000   \n",
       "1           going           0           0           1           0  0.000000   \n",
       "2          models           0           0           0           1  0.000000   \n",
       "3            task           0           0           1           0  0.000000   \n",
       "4          seeing           0           0           0           1  0.000000   \n",
       "5        language           1           0           0           2  0.083333   \n",
       "6       extrinsic           0           1           1           0  0.000000   \n",
       "7           embed           1           0           0           0  0.083333   \n",
       "8            help           0           0           1           0  0.000000   \n",
       "9            know           0           0           1           0  0.000000   \n",
       "10     recognizer           0           0           0           1  0.000000   \n",
       "11       improves           1           0           0           0  0.083333   \n",
       "12           much           1           0           0           0  0.083333   \n",
       "13         speech           0           0           0           2  0.000000   \n",
       "14     particular           0           0           1           0  0.000000   \n",
       "15       evaluate           1           0           0           0  0.083333   \n",
       "16        measure           1           0           0           0  0.083333   \n",
       "17          model           1           0           0           1  0.083333   \n",
       "18    improvement           0           0           1           0  0.000000   \n",
       "19          gives           0           0           0           1  0.000000   \n",
       "20            end           0           2           0           0  0.000000   \n",
       "21            way           1           0           1           0  0.083333   \n",
       "22      component           0           0           1           0  0.000000   \n",
       "23        running           0           0           0           1  0.000000   \n",
       "24     evaluation           0           2           1           0  0.000000   \n",
       "25           hand           0           0           1           0  0.000000   \n",
       "26    recognition           0           0           0           1  0.000000   \n",
       "27           best           1           0           0           0  0.083333   \n",
       "28       accurate           0           0           0           1  0.000000   \n",
       "29          twice           0           0           0           1  0.000000   \n",
       "30    application           2           0           0           0  0.166667   \n",
       "31            two           0           0           0           1  0.000000   \n",
       "32    performance           1           0           0           1  0.083333   \n",
       "33        compare           0           0           0           1  0.000000   \n",
       "34         called           0           1           0           0  0.000000   \n",
       "35  transcription           0           0           0           1  0.000000   \n",
       "36         really           0           0           1           0  0.000000   \n",
       "\n",
       "        TF_1      TF_2      TF_3      IDF   TFIDF_0   TFIDF_1   TFIDF_2  \\\n",
       "0   0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.083333  0.000000  0.60206  0.000000  0.000000  0.050172   \n",
       "2   0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.083333  0.000000  0.60206  0.000000  0.000000  0.050172   \n",
       "4   0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.111111  0.30103  0.025086  0.000000  0.000000   \n",
       "6   0.166667  0.083333  0.000000  0.30103  0.000000  0.050172  0.025086   \n",
       "7   0.000000  0.000000  0.000000  0.60206  0.050172  0.000000  0.000000   \n",
       "8   0.000000  0.083333  0.000000  0.60206  0.000000  0.000000  0.050172   \n",
       "9   0.000000  0.083333  0.000000  0.60206  0.000000  0.000000  0.050172   \n",
       "10  0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  0.60206  0.050172  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.60206  0.050172  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.111111  0.60206  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.083333  0.000000  0.60206  0.000000  0.000000  0.050172   \n",
       "15  0.000000  0.000000  0.000000  0.60206  0.050172  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  0.60206  0.050172  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.055556  0.30103  0.025086  0.000000  0.000000   \n",
       "18  0.000000  0.083333  0.000000  0.60206  0.000000  0.000000  0.050172   \n",
       "19  0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "20  0.333333  0.000000  0.000000  0.60206  0.000000  0.200687  0.000000   \n",
       "21  0.000000  0.083333  0.000000  0.30103  0.025086  0.000000  0.025086   \n",
       "22  0.000000  0.083333  0.000000  0.60206  0.000000  0.000000  0.050172   \n",
       "23  0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "24  0.333333  0.083333  0.000000  0.30103  0.000000  0.100343  0.025086   \n",
       "25  0.000000  0.083333  0.000000  0.60206  0.000000  0.000000  0.050172   \n",
       "26  0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "27  0.000000  0.000000  0.000000  0.60206  0.050172  0.000000  0.000000   \n",
       "28  0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "29  0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "30  0.000000  0.000000  0.000000  0.60206  0.100343  0.000000  0.000000   \n",
       "31  0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "32  0.000000  0.000000  0.055556  0.30103  0.025086  0.000000  0.000000   \n",
       "33  0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "34  0.166667  0.000000  0.000000  0.60206  0.000000  0.100343  0.000000   \n",
       "35  0.000000  0.000000  0.055556  0.60206  0.000000  0.000000  0.000000   \n",
       "36  0.000000  0.083333  0.000000  0.60206  0.000000  0.000000  0.050172   \n",
       "\n",
       "     TFIDF_3  \n",
       "0   0.033448  \n",
       "1   0.000000  \n",
       "2   0.033448  \n",
       "3   0.000000  \n",
       "4   0.033448  \n",
       "5   0.033448  \n",
       "6   0.000000  \n",
       "7   0.000000  \n",
       "8   0.000000  \n",
       "9   0.000000  \n",
       "10  0.033448  \n",
       "11  0.000000  \n",
       "12  0.000000  \n",
       "13  0.066896  \n",
       "14  0.000000  \n",
       "15  0.000000  \n",
       "16  0.000000  \n",
       "17  0.016724  \n",
       "18  0.000000  \n",
       "19  0.033448  \n",
       "20  0.000000  \n",
       "21  0.000000  \n",
       "22  0.000000  \n",
       "23  0.033448  \n",
       "24  0.000000  \n",
       "25  0.000000  \n",
       "26  0.033448  \n",
       "27  0.000000  \n",
       "28  0.033448  \n",
       "29  0.033448  \n",
       "30  0.000000  \n",
       "31  0.033448  \n",
       "32  0.016724  \n",
       "33  0.033448  \n",
       "34  0.000000  \n",
       "35  0.033448  \n",
       "36  0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# creating the frequency table \n",
    "freq_table = BoW_df.T\n",
    "colnames = [\"Sentence_\" + str(i) for i in range(len(freq_table.columns))]\n",
    "freq_table.columns = colnames\n",
    "\n",
    "# getting the number of documents in which a particular word occurs\n",
    "dfx = list(freq_table.astype(bool).sum(axis=1))\n",
    "\n",
    "freq_table.reset_index(inplace = True)\n",
    "freq_table = freq_table.rename(columns={'index': 'Word'})\n",
    "\n",
    "# calculating TF by dividing the total no of occurence of a word in a document divided by the total number of words in\n",
    "# the document\n",
    "\n",
    "N = len(freq_table.columns)-1\n",
    "for i in range(N):\n",
    "    col = \"Sentence_\" + str(i)\n",
    "    freq_table[\"TF_\" + str(i)] = 0.0\n",
    "    for j in range(len(freq_table)):\n",
    "        freq_table[\"TF_\" + str(i)][j] = freq_table[col][j] / freq_table[col].sum()\n",
    "\n",
    "# Calculating IDF\n",
    "freq_table[\"IDF\"] = 0.0\n",
    "\n",
    "N = len(sentences)\n",
    "for i in range(len(freq_table)):\n",
    "    freq_table[\"IDF\"][i] = np.log10(N / dfx[i])\n",
    "    # standard TF-IDF formula - log(N)/dfx\n",
    "    # sklearn TF-IDF formula - log(1+N)/(1 + dfx) + 1\n",
    "    # where N is the total no of documents \n",
    "\n",
    "# Calculating TFIDF which is the product of TF and IDF.\n",
    "# TFIDF for each word in each doc is given by the TF of the word in that doc divided by the IDF of the word\n",
    "\n",
    "for sent in range(len(sentences)):\n",
    "    freq_table[\"TFIDF_\" + str(sent)] = 0.0\n",
    "for k in range(len(freq_table)):\n",
    "    for sent in range(len(sentences)):\n",
    "        freq_table[\"TFIDF_\" + str(sent)][k] = freq_table[\"TF_\" + str(sent)][k] * freq_table[\"IDF\"][k]  \n",
    "\n",
    "freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thus</th>\n",
       "      <th>going</th>\n",
       "      <th>models</th>\n",
       "      <th>task</th>\n",
       "      <th>seeing</th>\n",
       "      <th>language</th>\n",
       "      <th>extrinsic</th>\n",
       "      <th>embed</th>\n",
       "      <th>help</th>\n",
       "      <th>know</th>\n",
       "      <th>recognizer</th>\n",
       "      <th>improves</th>\n",
       "      <th>much</th>\n",
       "      <th>speech</th>\n",
       "      <th>particular</th>\n",
       "      <th>evaluate</th>\n",
       "      <th>measure</th>\n",
       "      <th>model</th>\n",
       "      <th>improvement</th>\n",
       "      <th>gives</th>\n",
       "      <th>end</th>\n",
       "      <th>way</th>\n",
       "      <th>component</th>\n",
       "      <th>running</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>hand</th>\n",
       "      <th>recognition</th>\n",
       "      <th>best</th>\n",
       "      <th>accurate</th>\n",
       "      <th>twice</th>\n",
       "      <th>application</th>\n",
       "      <th>two</th>\n",
       "      <th>performance</th>\n",
       "      <th>compare</th>\n",
       "      <th>called</th>\n",
       "      <th>transcription</th>\n",
       "      <th>really</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>TFIDF_0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TFIDF_1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TFIDF_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TFIDF_3</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.016724</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             thus     going    models      task    seeing  language  \\\n",
       "TFIDF_0  0.000000  0.000000  0.000000  0.000000  0.000000  0.025086   \n",
       "TFIDF_1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "TFIDF_2  0.000000  0.050172  0.000000  0.050172  0.000000  0.000000   \n",
       "TFIDF_3  0.033448  0.000000  0.033448  0.000000  0.033448  0.033448   \n",
       "\n",
       "         extrinsic     embed      help      know  recognizer  improves  \\\n",
       "TFIDF_0   0.000000  0.050172  0.000000  0.000000    0.000000  0.050172   \n",
       "TFIDF_1   0.050172  0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "TFIDF_2   0.025086  0.000000  0.050172  0.050172    0.000000  0.000000   \n",
       "TFIDF_3   0.000000  0.000000  0.000000  0.000000    0.033448  0.000000   \n",
       "\n",
       "             much    speech  particular  evaluate   measure     model  \\\n",
       "TFIDF_0  0.050172  0.000000    0.000000  0.050172  0.050172  0.025086   \n",
       "TFIDF_1  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
       "TFIDF_2  0.000000  0.000000    0.050172  0.000000  0.000000  0.000000   \n",
       "TFIDF_3  0.000000  0.066896    0.000000  0.000000  0.000000  0.016724   \n",
       "\n",
       "         improvement     gives       end       way  component   running  \\\n",
       "TFIDF_0     0.000000  0.000000  0.000000  0.025086   0.000000  0.000000   \n",
       "TFIDF_1     0.000000  0.000000  0.200687  0.000000   0.000000  0.000000   \n",
       "TFIDF_2     0.050172  0.000000  0.000000  0.025086   0.050172  0.000000   \n",
       "TFIDF_3     0.000000  0.033448  0.000000  0.000000   0.000000  0.033448   \n",
       "\n",
       "         evaluation      hand  recognition      best  accurate     twice  \\\n",
       "TFIDF_0    0.000000  0.000000     0.000000  0.050172  0.000000  0.000000   \n",
       "TFIDF_1    0.100343  0.000000     0.000000  0.000000  0.000000  0.000000   \n",
       "TFIDF_2    0.025086  0.050172     0.000000  0.000000  0.000000  0.000000   \n",
       "TFIDF_3    0.000000  0.000000     0.033448  0.000000  0.033448  0.033448   \n",
       "\n",
       "         application       two  performance   compare    called  \\\n",
       "TFIDF_0     0.100343  0.000000     0.025086  0.000000  0.000000   \n",
       "TFIDF_1     0.000000  0.000000     0.000000  0.000000  0.100343   \n",
       "TFIDF_2     0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "TFIDF_3     0.000000  0.033448     0.016724  0.033448  0.000000   \n",
       "\n",
       "         transcription    really  \n",
       "TFIDF_0       0.000000  0.000000  \n",
       "TFIDF_1       0.000000  0.000000  \n",
       "TFIDF_2       0.000000  0.050172  \n",
       "TFIDF_3       0.033448  0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the TF and IDF steps from the dataframe and pretty printing the TF-IDF dataframe\n",
    "\n",
    "TF_IDF = freq_table.iloc[: , -len(sentences):]\n",
    "TF_IDF = TF_IDF.T\n",
    "TF_IDF.columns = list(freq_table[\"Word\"])\n",
    "TF_IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a python code to implement one-hot encoding of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>thus</th>\n",
       "      <th>going</th>\n",
       "      <th>models</th>\n",
       "      <th>task</th>\n",
       "      <th>seeing</th>\n",
       "      <th>language</th>\n",
       "      <th>embed</th>\n",
       "      <th>extrinsic</th>\n",
       "      <th>help</th>\n",
       "      <th>know</th>\n",
       "      <th>recognizer</th>\n",
       "      <th>how</th>\n",
       "      <th>and</th>\n",
       "      <th>improves</th>\n",
       "      <th>each</th>\n",
       "      <th>of</th>\n",
       "      <th>is</th>\n",
       "      <th>if</th>\n",
       "      <th>once</th>\n",
       "      <th>much</th>\n",
       "      <th>speech</th>\n",
       "      <th>particular</th>\n",
       "      <th>a</th>\n",
       "      <th>evaluate</th>\n",
       "      <th>only</th>\n",
       "      <th>it</th>\n",
       "      <th>measure</th>\n",
       "      <th>model</th>\n",
       "      <th>in</th>\n",
       "      <th>we</th>\n",
       "      <th>for</th>\n",
       "      <th>more</th>\n",
       "      <th>such</th>\n",
       "      <th>improvement</th>\n",
       "      <th>to</th>\n",
       "      <th>by</th>\n",
       "      <th>gives</th>\n",
       "      <th>end</th>\n",
       "      <th>which</th>\n",
       "      <th>way</th>\n",
       "      <th>at</th>\n",
       "      <th>component</th>\n",
       "      <th>running</th>\n",
       "      <th>can</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>hand</th>\n",
       "      <th>with</th>\n",
       "      <th>an</th>\n",
       "      <th>recognition</th>\n",
       "      <th>best</th>\n",
       "      <th>accurate</th>\n",
       "      <th>twice</th>\n",
       "      <th>application</th>\n",
       "      <th>two</th>\n",
       "      <th>performance</th>\n",
       "      <th>compare</th>\n",
       "      <th>called</th>\n",
       "      <th>transcription</th>\n",
       "      <th>really</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   the  thus  going  models  task  seeing  language  embed  extrinsic  help  \\\n",
       "0    1     0      0       0     0       0         1      1          0     0   \n",
       "1    0     0      0       0     0       0         0      0          1     0   \n",
       "2    1     0      1       0     1       0         0      0          1     1   \n",
       "3    1     1      0       1     0       1         1      0          0     0   \n",
       "\n",
       "   know  recognizer  how  and  improves  each  of  is  if  once  much  speech  \\\n",
       "0     0           0    1    1         1     0   1   1   0     0     1       0   \n",
       "1     0           0    0    0         0     0   0   1   0     0     0       0   \n",
       "2     1           0    0    0         0     0   0   1   1     0     0       0   \n",
       "3     0           1    0    1         0     1   1   0   0     1     0       1   \n",
       "\n",
       "   particular  a  evaluate  only  it  measure  model  in  we  for  more  such  \\\n",
       "0           0  1         1     0   1        1      1   1   0    0     0     0   \n",
       "1           0  0         0     0   0        0      0   0   0    0     0     1   \n",
       "2           1  1         0     1   0        0      0   1   0    0     0     0   \n",
       "3           0  0         0     0   0        0      1   0   1    1     1     0   \n",
       "\n",
       "   improvement  to  by  gives  end  which  way  at  component  running  can  \\\n",
       "0            0   1   0      0    0      0    1   0          0        0    0   \n",
       "1            0   1   0      0    1      0    0   0          0        0    0   \n",
       "2            1   1   0      0    0      0    1   1          1        0    0   \n",
       "3            0   0   1      1    0      1    0   0          0        1    1   \n",
       "\n",
       "   evaluation  hand  with  an  recognition  best  accurate  twice  \\\n",
       "0           0     0     0   1            0     1         0      0   \n",
       "1           1     0     0   0            0     0         0      0   \n",
       "2           1     1     0   0            0     0         0      0   \n",
       "3           0     0     1   0            1     0         1      1   \n",
       "\n",
       "   application  two  performance  compare  called  transcription  really  \n",
       "0            1    0            1        0       0              0       0  \n",
       "1            0    0            0        0       1              0       0  \n",
       "2            0    0            0        0       0              0       1  \n",
       "3            0    1            1        1       0              1       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# getting list of unique words in each sentence\n",
    "ohe_list = []\n",
    "for s in filteredsent:\n",
    "    ohe_list.append(list(set(s.split())))\n",
    "\n",
    "# all the unique words in the text\n",
    "corpus = list(set(itertools.chain(*ohe_list)))\n",
    "\n",
    "# creating a dataframe to store the OHE\n",
    "ohe = pd.DataFrame(np.zeros((len(filteredsent),len(corpus)),dtype = int), columns = corpus)\n",
    "# when a word from the list of unique words from each sentence is come in contact, set the value of that word in that\n",
    "# particular sentence number #th row to 1\n",
    "sentno = 0\n",
    "for s in ohe_list:\n",
    "    for w in s:\n",
    "        ohe[w][sentno] = 1\n",
    "    sentno = sentno + 1\n",
    "ohe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
